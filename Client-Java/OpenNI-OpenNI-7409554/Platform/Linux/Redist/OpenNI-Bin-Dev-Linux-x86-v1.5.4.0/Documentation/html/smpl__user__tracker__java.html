<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<title>OpenNI 1.5.4: UserTracker.java - sample program (Java)</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link href="doxygen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<!-- Generated by Doxygen 1.6.3 -->
<div class="navigation" id="top">
  <div class="tabs">
    <ul>
      <li><a href="main.html"><span>Main&nbsp;Page</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div class="navpath"><a class="el" href="main.html">OpenNI Overview</a>&nbsp;&raquo;&nbsp;<a class="el" href="smpls__n__guides.html">Samples and Guides</a>&nbsp;&raquo;&nbsp;<a class="el" href="smpls.html">Sample Programs for the OpenNI API</a>
  </div>
</div>
<div class="contents">


<h1><a class="anchor" id="smpl_user_tracker_java">UserTracker.java - sample program (Java) </a></h1><p><b>Source file:</b> Click the following link to view the source code file:</p>
<ul>
<li>UserTracker.java</li>
</ul>
<p>The User Tracker sample program demonstrates the OpenNI code for tracking the movement of a user through its skeleton capability. This sample program is encapsulated in the org.OpenNI.Samples.UserTracker.jar (java archive).</p>
<p>This major section describes the OpenNI program code of the UserTracker sample program written in the Java language.</p>
<p>The documentation describes the program code from the top of the program file(s) to bottom, unless otherwise indicated.</p>
<h2><a class="anchor" id="utj_main_run">
Main Run Routine</a></h2>
<p>The main <code>Run()</code> routine shown in the following code block is located in the <code>UserTrackerApplication.java</code> file. The main program loop calls the <code>updateDepth()</code> function, which is located in the <code>UserTracker.java </code> file. The <code>updateDepth()</code> function causes the OpenNI system to make OpenNI user data available with each execution of the loop. The <code>repaint()</code> function then causes the refresh of the user data display. </p>
<div class="fragment"><pre class="fragment">        <span class="keywordtype">void</span> run()
        {
            <span class="keywordflow">while</span>(shouldRun) {
                viewer.updateDepth();
                viewer.repaint();
            }
            frame.dispose();
        }
</pre></div><p><b>FILE: UserTracker.java</b></p>
<p>All the following sections document the OpenNI code in the <code>UserTracker.java </code> file.</p>
<h2><a class="anchor" id="utj_glb_dcl_blk_ref">
"Declaration Block" section</a></h2>
<p>The reader may find it convenient to study the global declaration block before continuing to study the code statements. The global declaration block is documented later in this section, corresponding to its position in the program file &ndash; see <a class="el" href="smpl__user__tracker__java.html#utj_glb_dcl_blk">Global Declaration Block</a>.</p>
<h2><a class="anchor" id="utj_event_handlers">
Declarations of Event Handlers</a></h2>
<p>The following sections describe the event handlers this sample program requires, describing the nature of the events themselves and what is done inside the handlers. Detected'</p>
<p>A typical order of invocation of the events in the default configuration, where online-calibration is enabled, would be: 1. 'New User' event 2. 'Calibration Complete' event 3. 'Lost User' event</p>
<p>Online-calibration enables the acquisition of a skeleton without the need for poses. The events are described below in order of their declaration in the source code.</p>
<p>Note: When online-calibration is turned off ( which is <em>not </em> the default configuration) a 'Pose Detected' event would typically occur after the 'New User' event and before the Calibration Complete' event.</p>
<h2><a class="anchor" id="utj_newuser_ev_hndlr">
'New User' event handler</a></h2>
<p>The <b>'New User' event</b> signals that a new user has now been recognized in the scene. A new user is a user that was not previously recognized in the scene, and is now recognized in the scene. The user is identified by a persistent ID.</p>
<p>An example <b>'New User' event handler</b> is as below. On detecting a new user, the handler checks if a pose is needed. If it is, it calls <a class="el" href="classxn_1_1_pose_detection_capability.html#a8ba21d0b1a6ba12a89fd0100e980121a">to</a> start pose detection. If not, it requests calibration. </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">class </span>NewUserObserver <span class="keyword">implements</span> IObserver&lt;UserEventArgs&gt;
            {
                @Override
                <span class="keyword">public</span> <span class="keywordtype">void</span> update(IObservable&lt;UserEventArgs&gt; observable,
                        UserEventArgs args)
                {
                    System.out.println(<span class="stringliteral">&quot;New user &quot;</span> + args.getId());
                    <span class="keywordflow">try</span>
                    {
                        <span class="keywordflow">if</span> (skeletonCap.needPoseForCalibration())
                        {
                            poseDetectionCap.StartPoseDetection(calibPose, args.getId());
                        }
                        <span class="keywordflow">else</span>
                        {
                            skeletonCap.requestSkeletonCalibration(args.getId(), <span class="keyword">true</span>);
                        }
                    } <span class="keywordflow">catch</span> (StatusException e)
                    {
                        e.printStackTrace();
                    }
                }
            }
</pre></div><h2><a class="anchor" id="utj_lostuser_ev_hndlr">
'Lost User' event handler</a></h2>
<p>The <b>'Lost User' event</b> signals that a user has been lost from the list of previously recognized users in the scene. The exact meaning of a lost user is decided by the developer of the <a class="el" href="classxn_1_1_user_generator.html">xn::UserGenerator</a>. However, a typical implementation would define that a lost user is a previously recognized user that then exits the scene and does not return, even after a 'Lost User' timeout has elapsed. Thus this event might be raised only after some delay after the user actually exited the scene.</p>
<p>An example <b>'Lost User' event handler</b> is as below. On detecting that an existing user has been lost, the handler deletes the user's entry from the <code>joints</code> array &ndash; for a description of the <code>joints</code> array see <a class="el" href="smpl__user__tracker__net.html#utcs_init_joints_array">Initializes the 'joints' Array</a> <code>joints</code>. </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">class </span>LostUserObserver <span class="keyword">implements</span> IObserver&lt;UserEventArgs&gt;
            {
                @Override
                <span class="keyword">public</span> <span class="keywordtype">void</span> update(IObservable&lt;UserEventArgs&gt; observable,
                        UserEventArgs args)
                {
                    System.out.println(<span class="stringliteral">&quot;Lost use &quot;</span> + args.getId());
                    joints.remove(args.getId());
                }
            }
</pre></div><h2><a class="anchor" id="utj_calibcmplt_ev_hndlr">
'Calibration Complete' event handler</a></h2>
<p>The <b>'Calibration Complete' event</b> signals that a specific user's skeleton has now completed the calibration process, and provides a result status. The user is identified by the ID given by the <code>e.ID</code> parameter.</p>
<p>An example <b>'Calibration Complete' event handler</b> is as below. On detecting that the calibration has completed, the handler tests whether the calibration process was completed successfully. If yes, that means that a user has been detected and calibrated, and enough information has been obtained to create a skeleton to represent the user.</p>
<p>The handler startTracking(then advances the processing to the next stage, i.e., to call <a class="el" href="classxn_1_1_skeleton_capability.html#a9b6c1de717298ff1540e32c6d2c02260">xn::SkeletonCapability::StartTracking()</a> to start tracking the skeleton, which represents a human user body, within a real-life (3D) scene for analysis, interpretation, and use by the application. (Description continued after the code.) </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">class </span>CalibrationCompleteObserver <span class="keyword">implements</span> IObserver&lt;CalibrationProgressEventArgs&gt;
            {
                @Override
                <span class="keyword">public</span> <span class="keywordtype">void</span> update(IObservable&lt;CalibrationProgressEventArgs&gt; observable,
                        CalibrationProgressEventArgs args)
                {
                    System.out.println(<span class="stringliteral">&quot;Calibraion complete: &quot;</span> + args.getStatus());
                    <span class="keywordflow">try</span>
                    {
                    <span class="keywordflow">if</span> (args.getStatus() == CalibrationProgressStatus.OK)
                    {
                        System.out.println(<span class="stringliteral">&quot;starting tracking &quot;</span>  +args.getUser());
                            skeletonCap.xn::(args.getUser());
                            joints.put(<span class="keyword">new</span> Integer(args.getUser()), <span class="keyword">new</span> HashMap&lt;SkeletonJoint, SkeletonJointPosition&gt;());
                    }
                    <span class="keywordflow">else</span>
                    {
                        <span class="keywordflow">if</span> (skeletonCap.needPoseForCalibration())
                        {
                            poseDetectionCap.StartPoseDetection(calibPose, args.getUser());
                        }
                        <span class="keywordflow">else</span>
                        {
                            skeletonCap.requestSkeletonCalibration(args.getUser(), <span class="keyword">true</span>);
                        }
                    }
                    } <span class="keywordflow">catch</span> (StatusException e)
                    {
                        e.printStackTrace();
                    }
                }
            }
</pre></div><p>In the above, the handler then creates, for the new user, a new user entry in the <a class="el" href="smpl__user__tracker__net.html#utcs_init_joints_array">Initializes the 'joints' Array</a> <code>joints</code> array. This is a database for users and skeletons. In the <code>joints</code> database, each user has a list of entries where each entry is a data pair: </p>
<div class="fragment"><pre class="fragment">
			&lt;SkeletonJoint, SkeletonJointPosition&gt; 
		</pre></div><p>In the above handler, if the calibration process failed, the handler restarts the whole calibration sequence.The way the handler restarts the calibration sequence depends on whether the specific generator demands detecting a pose before starting calibration</p>
<h2><a class="anchor" id="utj_posedetect_ev_hndlr">
'Pose Detected' event handler</a></h2>
<p>The <b>'Pose Detected' event</b> signals that a human user made the pose named in the call to the StartPoseDetection() method. The user is designated with the ID given by the <code> args.getUser() </code> parameter.</p>
<p>The PoseDetected observer is only relevant when not in Online Calibration mode (when <code>needPoseForCalibration </code> is <code>true</code>).</p>
<p>An example <b>'Pose Detected' event handler</b> is as below. On detecting that a pose has been detected, the handler calls <a class="el" href="classxn_1_1_pose_detection_capability.html#a5ecc3fc3aa1fbd7fbe0a01d3d0c105bc">stopPoseDetection()</a> to stop pose detection. The handler then calls <a class="el" href="classxn_1_1_skeleton_capability.html#a3428d28764b594a2816f5aa314188234">requestSkeletonCalibration()</a> to start calibration. The <code>true</code> disregards any previous calibration and forces a new calibration. </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">class </span>PoseDetectedObserver <span class="keyword">implements</span> IObserver&lt;PoseDetectionEventArgs&gt;
            {
                @Override
                <span class="keyword">public</span> <span class="keywordtype">void</span> update(IObservable&lt;PoseDetectionEventArgs&gt; observable,
                        PoseDetectionEventArgs args)
                {
                    System.out.println(<span class="stringliteral">&quot;Pose &quot;</span> + args.getPose() + <span class="stringliteral">&quot; detected for &quot;</span> + args.getUser());
                    <span class="keywordflow">try</span>
                    {
                        poseDetectionCap.stopPoseDetection(args.getUser());
                        skeletonCap.requestSkeletonCalibration(args.getUser(), <span class="keyword">true</span>);
                    } 
                    <span class="keywordflow">catch</span> (StatusException e)
                    {
                        e.printStackTrace();
                    }
                }
            }
</pre></div><h2><a class="anchor" id="utj_glb_dcl_blk">
Global Declaration Block</a></h2>
<p>The global declaration block is located after the events. The declarations define the OpenNI objects required for building the OpenNI production graph. The production graph is the main object model in OpenNI. </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">private</span> OutArg&lt;ScriptNode&gt; scriptNode;
            <span class="keyword">private</span> Context context;
            <span class="keyword">private</span> DepthGenerator depthGen;
            <span class="keyword">private</span> UserGenerator userGen;
            <span class="keyword">private</span> SkeletonCapability skeletonCap;
            <span class="keyword">private</span> PoseDetectionCapability poseDetectionCap;
</pre></div><p>Each of these declarations is described separately in the following paragraphs.</p>
<p>the <a class="el" href="classxn_1_1_script_node.html">xn::ScriptNode</a> object loads an XML script from a file or string, and then runs the XML script to build a production graph. The ScriptNode object must be kept alive as long as the other nodes are needed. </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">private</span> OutArg&lt;ScriptNode&gt; scriptNode;
</pre></div><p>The <em>production graph</em> is a network of software objects - called production nodes - that can identify blobs as hands or human users. In this sample program the production graph identifies blobs as human users, and tracks them as they move.</p>
<p>a <a class="el" href="classxn_1_1_context.html">xn::Context</a> object is a workspace in which the application builds an OpenNI production graph. </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">private</span> Context context;
</pre></div><p>a <a class="el" href="classxn_1_1_depth_generator.html">xn::DepthGenerator</a> node generates a depth map. Each map pixel value represents a distance from the sensor. </p>
<div class="fragment"><pre class="fragment">            DepthGenerator depthGen;
</pre></div><p>A <a class="el" href="classxn_1_1_user_generator.html">xn::UserGenerator</a> node generates data describing users that it recognizes in the scene, identifying each user individually and thus allowing actions to be done on specific users. The single UserGenerator node gets data for all users appearing in the scene. </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">private</span> UserGenerator userGen;
</pre></div><p>The <a class="el" href="classxn_1_1_skeleton_capability.html">xn::SkeletonCapability</a> lets the node generate a skeleton representation for each human user generated by the node. Each UserGenerator node can have exactly one skeleton representation. The skeleton data includes the location of the skeletal joints, the ability to track skeleton positions and the user calibration capabilities.</p>
<p>To help track a user's skeleton, the <a class="el" href="classxn_1_1_skeleton_capability.html">xn::SkeletonCapability</a> can execute a calibration process to measure and record the lengths of the human user's limbs. </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">private</span> SkeletonCapability skeletonCap;
</pre></div><p>The PoseDetectionCapability object lets a <a class="el" href="classxn_1_1_user_generator.html">UserGenerator</a> node recognize when the user is posed in a specific position. </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">private</span> PoseDetectionCapability poseDetectionCap;
</pre></div><h2><a class="anchor" id="utj_func_main">
Main Program - UserTracker() "try" - How should I title this</a></h2>
<p>All the following are in the Try{} clause. Exceptions are used for error handling.</p>
<h3><a class="anchor" id="svj_scrpt_sets_up_pg">
Uses a Script to Set up a Context and Production Graph</a></h3>
<p>The following code block uses a script to set up a context and a production graph. the <a class="el" href="classxn_1_1_context.html#aa0f2dff24c434ed56b44332456ea9502">createFromXmlFile()</a> method, which is a shorthand combination of two other initialization methods, initializes the context object and then creates a production graph from an XML file. The XML script file describes all the nodes you want to create. For each node description in the XML file, this method creates a node in the production graph. </p>
<div class="fragment"><pre class="fragment">                scriptNode = <span class="keyword">new</span> OutArg&lt;ScriptNode&gt;();
                context = Context.createFromXmlFile(SAMPLE_XML_FILE, scriptNode);               
</pre></div><h3><a class="anchor" id="utj_get_dg_node_from_pg">
Gets a DepthGenerator Node from the Production Graph</a></h3>
<p>The following statement creates and returns a reference to a <a class="el" href="classxn_1_1_depth_generator.html">DepthGenerator</a> node. The create() method can return a reference to an existing DepthGenerator node if one already exists in the production graph created from the XML. If no DepthGenerator node already exists, this method creates a new DepthGenerator node and returns a reference to the new node. </p>
<div class="fragment"><pre class="fragment">                depthGen = DepthGenerator.create(context);
</pre></div><p>The following statement places the latest data generated in an 'easy-to-access' buffer. In OpenNI terminology: "the node's getMetaData() method gets the node's data that is designated as 'metadata to be placed in the node's metadata object'". The code copies the node's frame data and configuration to a metadata object - (<code>depthMD</code>). This metadata object is then termed the 'frame object'. </p>
<div class="fragment"><pre class="fragment">                DepthMetaData depthMD = depthGen.getMetaData();
</pre></div><h3><a class="anchor" id="utj_setup_hist_array">
Defines the Histogram Array</a></h3>
<p>The following defines the histogram array. This array is a key part of this sample program (although this code is not OpenNI specific).</p>
<p><code>histogram[]</code> is an array with MAX_DEPTH entries (10,000 at the time of writing), one entry for each depth value that the sensor can output. This array is used for the histogram feature in the <code>DrawDepthMap()</code> function later in this file.</p>
<p>The histogram feature of this sample program creates a gradient of the scene's depth scene, from dark (far away) to light (close), regardless of the color. Each entry of the array is a counter for the corresponding depth value.</p>
<p><code>histogram[]</code> is used later in this application file to build the histogram. The application scans the depth map. For each depth pixel the application inspects the depth value, and for that value's entry in the array, it increments its counter by 1. The application performs also further processing, as described later in the description.</p>
<div class="fragment"><pre class="fragment">                histogram = <span class="keyword">new</span> <span class="keywordtype">float</span>[10000];
</pre></div><p>The following code accesses some attributes of the frame data's associated configuration properties: <a class="el" href="classxn_1_1_map_meta_data.html#a02936294900df06cbe9661dd004af570">xn::MapMetaData::FullXRes</a> "getFullXRes()" and <a class="el" href="classxn_1_1_map_meta_data.html#a864b583a263d8233cdfc5d29c609e62b">xn::MapMetaData::FullYRes</a> "getFullYRes()" are the full frame resolution, i.e., the entire field-of-view, ignoring cropping of the FOV in the scene. These values are used later for allocationg memory for an image bufffer. </p>
<div class="fragment"><pre class="fragment">                width = depthMD.getFullXRes();
                height = depthMD.getFullYRes();
</pre></div><h3><a class="anchor" id="utj_create_ug_node">
Creates a UserGenerator Node</a></h3>
<p>The following program code creates a <a class="el" href="classxn_1_1_user_generator.html">UserGenerator</a> node and then gets two capabilities of the node: a <a class="el" href="classxn_1_1_skeleton_capability.html">SkeletonCapability</a> object and a <a class="el" href="classxn_1_1_pose_detection_capability.html">PoseDetectionCapability</a> object. The code then assigns references to the two capabilities for easy access to them. </p>
<div class="fragment"><pre class="fragment">                userGen = UserGenerator.create(context);
                skeletonCap = userGen.getSkeletonCapability();
                poseDetectionCap = userGen.getPoseDetectionCapability();
</pre></div><p>Each of these declarations is described separately in the following paragraphs.</p>
<p>The following statement creates and returns a reference to a <a class="el" href="classxn_1_1_user_generator.html">UserGenerator</a> node. The create() method can return a reference to an existing UserGenerator node if one already exists in the production graph created from the XML. If no UserGenerator node already exists, this method creates a new UserGenerator node and returns a reference to the new node. </p>
<div class="fragment"><pre class="fragment">                userGen = UserGenerator.create(context);
</pre></div><p>The following two statements get a <a class="el" href="classxn_1_1_skeleton_capability.html">xn::SkeletonCapability</a> object for accessing Skeleton functionality and a PoseDetectionCapability for accessing Pose Detection functionality. </p>
<div class="fragment"><pre class="fragment">                skeletonCap = userGen.getSkeletonCapability();
                poseDetectionCap = userGen.getPoseDetectionCapability();
</pre></div><h3><a class="anchor" id="utj_init_event_hndlrs">
Initialize Event Handlers</a></h3>
<p>The following code block registers two event handlers for the UserGenerator node, and handlers for its two capabilities: the <a class="el" href="classxn_1_1_skeleton_capability.html">SkeletonCapability</a> object and a <a class="el" href="classxn_1_1_pose_detection_capability.html">PoseDetectionCapability</a> object. </p>
<div class="fragment"><pre class="fragment">                userGen.getNewUserEvent().addObserver(<span class="keyword">new</span> NewUserObserver());
                userGen.getLostUserEvent().addObserver(<span class="keyword">new</span> LostUserObserver());
                skeletonCap.getCalibrationCompleteEvent().addObserver(<span class="keyword">new</span> CalibrationCompleteObserver());
                poseDetectionCap.getPoseDetectedEvent().addObserver(<span class="keyword">new</span> PoseDetectedObserver());
</pre></div><p>See <a class="el" href="smpl__user__tracker__java.html#utj_event_handlers">Declarations of Event Handlers</a> for the descriptions of these events and their usages.</p>
<h3><a class="anchor" id="utj_init_joints_array">
Initializes the 'joints' Array</a></h3>
<p>The following statement initializes the 'joints' array. This array is a list of mapping entries of the following structure: <br/>
 </p>
<div class="fragment"><pre class="fragment">
				 (Integer-&gt;(SkeletonJoint-&gt;SkeletonJointPosition))*)
			</pre></div><p> Meaning for each user ID (the Integer), we keep a mapping of the current position of each joint.</p>
<p>Each entry maps a particular <a class="el" href="_xn_types_8h.html#a7713dc7b4e1415ffe6c835c5979d65f4">xn::XnSkeletonJoint</a> skeleton joint (an ID identifying a particular joint in the skeleton) to its <code>SkeletonJointPosition</code> "3D position". </p>
<div class="fragment"><pre class="fragment">                joints = <span class="keyword">new</span> HashMap&lt;Integer, HashMap&lt;SkeletonJoint,SkeletonJointPosition&gt;&gt;();
</pre></div><h3><a class="anchor" id="utj_set_ske_prfl">
Sets the Skeleton Profile</a></h3>
<p>In the following statement, the <a class="el" href="classxn_1_1_skeleton_capability.html#ab07ee49ccdb7278945af4144bb115c15">setSkeletonProfile()</a> sets the skeleton profile. The skeleton profile specifies which joints are to be active, and which to be inactive. The <a class="el" href="classxn_1_1_user_generator.html">xn::UserGenerator</a> node generates output data for the active joints only. This profile applies to all skeletons that the <a class="el" href="classxn_1_1_user_generator.html">xn::UserGenerator</a> node generates. In this case, the method sets all joints to be active. </p>
<div class="fragment"><pre class="fragment">                skeletonCap.setSkeletonProfile(SkeletonProfile.ALL);
</pre></div><h3><a class="anchor" id="utcs_start_node_generating">
Starts the Node Generating</a></h3>
<p>The following statement ensures that all created <a class="el" href="glossary.html#dict_gen_node">generator nodes</a> are in Generating state. Each node can be in Generating state or Non-Generating state. When a node is in Generating state it generates data. </p>
<div class="fragment"><pre class="fragment">                context.startGeneratingAll();
</pre></div><h2><a class="anchor" id="utj_calcHist">
CalcHist() - Using the Depth Values to Build an Accumulative Histogram</a></h2>
<p>CalcHist() &ndash; This function calculates an enhanced accumulative histogram to present a frequency distribution of a scene's depth. The goal is that the histogram presents a relatively "closer" depth (i.e., a smaller depth value than another depth value [e.g., 100 is closer than 200], which represents a distance closer to the human user</p>
<p>The following code block uses the depth values to build an accumulative histogram of frequency of occurrence of each depth value. The resulting <code>histogram</code> array holds the percentage of the pixels that are further away from the sensor than the distance its index represents in mm (greater than, not greater than or equal). Thus a 'closer depth index' (i.e., a depth index that represents a depth that is closer to the human user. For example, an index of 100 corresponds to a distance of 900 mm. The furthest distance is represented by the 0 index.</p>
<p>The <b>depthMD.DepthMapPtr()</b> method returns a pointer to the Depth Map to access each value in the depth buffer. The depth value is then used as an index into the histogram[] array. </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">private</span> <span class="keywordtype">void</span> calcHist(ShortBuffer depth)
            {
                <span class="comment">// reset</span>
                <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; histogram.length; ++i)
                    histogram[i] = 0;
                
                depth.rewind();

                <span class="keywordtype">int</span> points = 0;
                <span class="keywordflow">while</span>(depth.remaining() &gt; 0)
                {
                    <span class="keywordtype">short</span> depthVal = depth.get();
                    <span class="keywordflow">if</span> (depthVal != 0)
                    {
                        histogram[depthVal]++;
                        points++;
                    }
                }
                
                <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 1; i &lt; histogram.length; i++)
                {
                    histogram[i] += histogram[i-1];
                }

                <span class="keywordflow">if</span> (points &gt; 0)
                {
                    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 1; i &lt; histogram.length; i++)
                    {
                        histogram[i] = 1.0f - (histogram[i] / (float)points);
                    }
                }
            }
</pre></div><h2><a class="anchor" id="utj_update_depth_fn">
updateDepth() method: Updating the Depth Map</a></h2>
<p>the <a class="el" href="classxn_1_1_context.html#a17fab043d7b6d60728511527a1d5c090">waitAnyUpdateAll()</a> method in the following statement updates all generator nodes in the context to their latest available data, first waiting for all nodes to have new data available. The application can then get the data, (for example, using a getMetaData () method)). This method has a timeout. The application must do the update before getting the dat, otherwise it would get values from the previous frame instead of the current one. </p>
<div class="fragment"><pre class="fragment">            context.waitAnyUpdateAll();
</pre></div><p>The following statement sets up the frame object. For more explanation on this, see <a class="el" href="conc__meta__data.html">Frame Objects and Metadata Objects</a>, <a class="el" href="glossary.html#glos_frame_object">Frame Objects</a>, and <a class="el" href="glossary.html#frame_data">Frame Data (Data Frame)</a>. </p>
<div class="fragment"><pre class="fragment">            DepthMetaData depthMD = depthGen.getMetaData();
            SceneMetaData sceneMD = userGen.getUserPixels(0);
</pre></div><p>The following code block creates a convenient buffer for the depth map and then calls the calcHist() method to calculate the histogram. </p>
<div class="fragment"><pre class="fragment">            ShortBuffer scene = sceneMD.getData().createShortBuffer();
            ShortBuffer depth = depthMD.getData().createShortBuffer();
            calcHist(depth);
            depth.rewind();
</pre></div><p>The following code block builds an image buffer according to the frequency of each depth value in the histogram. </p>
<div class="fragment"><pre class="fragment">            <span class="keywordflow">while</span>(depth.remaining() &gt; 0)
            {
                <span class="keywordtype">int</span> pos = depth.position();
                <span class="keywordtype">short</span> pixel = depth.get();
                imgbytes[pos] = (byte)histogram[pixel];
                imgbytes[3*pos] = 0;
                imgbytes[3*pos+1] = 0;
                imgbytes[3*pos+2] = 0;                  

                <span class="keywordflow">if</span> (drawBackground || pixel != 0)
                {
                    <span class="keywordtype">int</span> colorID = user % (colors.length-1);
                    <span class="keywordflow">if</span> (user == 0)
                    {
                        colorID = colors.length-1;
                    }
                    <span class="keywordflow">if</span> (pixel != 0)
                    {
                        <span class="keywordtype">float</span> histValue = histogram[pixel];
                        imgbytes[3*pos] = (byte)(histValue*colors[colorID].getRed());
                        imgbytes[3*pos+1] = (byte)(histValue*colors[colorID].getGreen());
                        imgbytes[3*pos+2] = (byte)(histValue*colors[colorID].getBlue());
                    }
                }
            }       
</pre></div><h2><a class="anchor" id="utj_get_joint">
getJoint() method</a></h2>
<p>The <code>getJoint()</code> method is called multiple times by the <code>getJoints()</code> method (see further below - <a href="#getJoints_method">" getJoints()_method"</a>). The <code>getJoint()</code> method first translates the joint's coordinates to projective coordinates, in order to be able to show them on screen. Then the method gets one of the joints of a skeleton and adds it to the easy-to-access <code>joints</code> map table. In OpenNI, some of these <em>joints</em> are actual joints, in the conventional sense as termed by the English language, for example, SkeletonJoint.LEFT_ELBOW and SkeletonJoint.LEFT_WRIST; and in addition some <em>limbs</em> are also termed in OpenNI as joints, for example, SkeletonJoint.HEAD and SkeletonJoint.LEFT_HAND. OpenNI defines <em>all</em> these joints with a single position coordinate. </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">public</span> <span class="keywordtype">void</span> getJoint(<span class="keywordtype">int</span> user, SkeletonJoint joint) <span class="keywordflow">throws</span> StatusException
            {
                SkeletonJointPosition pos = skeletonCap.getSkeletonJointPosition(user, joint);
                <span class="keywordflow">if</span> (pos.getPosition().getZ() != 0)
                {
                    joints.get(user).put(joint,
                    <span class="keyword">new</span> SkeletonJointPosition(  depthGen.convertRealWorldToProjective(pos.getPosition()),pos.getConfidence()));
                }
                <span class="keywordflow">else</span>
                {
                    joints.get(user).put(joint, <span class="keyword">new</span> SkeletonJointPosition(<span class="keyword">new</span> Point3D(), 0));
                }
            }
</pre></div><p> The above statements are explained separately, as follows.</p>
<p>the <a class="el" href="classxn_1_1_skeleton_capability.html">getSkeletonJointPosition()</a> method gets the position of one of the skeleton joints in the most recently generated data for a specified user. </p>
<div class="fragment"><pre class="fragment">            SkeletonJointPosition pos = skeletonCap.getSkeletonJointPosition(user, joint);
</pre></div><p>A sanity check is then performed to check that the joint does not have zero depth since translation between coordinate systems does not work with a depth zero. </p>
<div class="fragment"><pre class="fragment">            <span class="keywordflow">if</span> (pos.getPosition().getZ() != 0)
</pre></div><p>If the position is not zero depth, a new <a class="el" href="_xn_types_8h.html#a69cf000072ccb570b587429627bc484a">xn::XnSkeletonJointPosition</a> object is created for the joint and inserted into the <code>joints</code> mapping table. The position structure comprises a 3D position and a confidence that the joint is in fact in that position. The 3D position structure is a projective coordinate, so <code>convertRealWorldToProjective()</code> is used to convert the real world cordinate to a projective coordinate. </p>
<div class="fragment"><pre class="fragment">            joints.get(user).put(joint,
                        <span class="keyword">new</span> SkeletonJointPosition(
                             depthGen.convertRealWorldToProjective(pos.getPosition()),
                                                                    pos.getConfidence()));
</pre></div><p>Else a (0,0,0) point is added, with confidence 0, as follows.</p>
<div class="fragment"><pre class="fragment">            <span class="keywordflow">else</span>
            {
                joints.get(user).put(joint, <span class="keyword">new</span> SkeletonJointPosition(<span class="keyword">new</span> Point3D(), 0));
            }
</pre></div><h2><a class="anchor" id="utj_drawing_the_ske">
Drawing the Complete Skeleton</a></h2>
<p>The following sections show how to get all the individual joints, and then use them to draw a complete skeleton.</p>
<h2><a class="anchor" id="utj_get_joints">
getJoints() method</a></h2>
<p><a class="anchor" id=" getJoints_method"></a>"This " method updates the <code>joints</code> database so that it holds all the current joint positions. This method comprises successive calls to the <code>getJoint()</code> method to get all the joints in a skeleton. The following code block shows the first few statements in this method, which get the HEAD and NECK joints. The subsequent statements get the rest of the joints. </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">public</span> <span class="keywordtype">void</span> getJoints(<span class="keywordtype">int</span> user) <span class="keywordflow">throws</span> StatusException
            {
                getJoint(user, SkeletonJoint.HEAD);
                getJoint(user, SkeletonJoint.NECK);
                 ... 
            }
</pre></div><h2><a class="anchor" id="utj_draw_line">
drawLine() method</a></h2>
<p>This method draws a limb of the avatar representation of a human user by drawing a line between two adjacent OpenNI <a class="el" href="_xn_types_8h.html#a7713dc7b4e1415ffe6c835c5979d65f4">joints</a> passed as parameters to this function. The two joints are points in the scene. The two adjacent joints come from the <code>jointHash</code> mapping table (whose scope is in the drawSkeleton() method) through the <em>jointHash</em> parameter. </p>
<div class="fragment"><pre class="fragment">                <span class="keywordtype">void</span> drawLine(Graphics g, HashMap&lt;SkeletonJoint, SkeletonJointPosition&gt; jointHash, SkeletonJoint joint1, SkeletonJoint joint2)
            {
                ...
            }
</pre></div><p>In the above, the <code>jointHash</code> parameter passes in the mapping list of joint-to-position for all the joints of a apecified user. The <code>jointHash</code> parameter is of type <code>Dictionary&lt;SkeletonJoint, SkeletonJointPosition&gt; dict</code>. The two parameters <code>joint1</code> and <code>joint2</code> are both enum types, specifying a particular joint in the skeleton. <code>joint1</code> and <code>join2</code> are used to index the <code>jointHash</code> list to get the corresponding positions of the joints.</p>
<p>Statements of this function are explained below.</p>
<p>First, the method gets the cordinates of the two joints. Then the method checks confidence, which is the likelihood that a point is real, and if either of them have a zero confidence the method fails. This is shown in the code block below. </p>
<div class="fragment"><pre class="fragment">            Point3D pos1 = jointHash.get(joint1).getPosition();
            Point3D pos2 = jointHash.get(joint2).getPosition();

            <span class="keywordflow">if</span> (jointHash.get(joint1).getConfidence() == 0 || jointHash.get(joint1).getConfidence() == 0)
                <span class="keywordflow">return</span>;
</pre></div><p>The following code block uses Java Graphic object to draw the avatar's limb by drawing a line between the two adjacent points. It uses the locations <code>pos1 </code> and <code>pos2</code> obtained above. </p>
<div class="fragment"><pre class="fragment">            g.drawLine((<span class="keywordtype">int</span>)pos1.getX(), (int)pos1.getY(), (int)pos2.getX(), (int)pos2.getY());
</pre></div><h2><a class="anchor" id="utj_draw_skel">
drawSkeleton() method</a></h2>
<p>This method draws the complete skeleton for a specified user. It draws the skeleton by callng the drawLine() method successive times to draw connecting lines between each adjacent pair of joints. The following code block shows some sample statements: </p>
<div class="fragment"><pre class="fragment">            <span class="keyword">public</span> <span class="keywordtype">void</span> drawSkeleton(Graphics g, <span class="keywordtype">int</span> user) <span class="keywordflow">throws</span> StatusException
            {
                getJoints(user);
                HashMap&lt;SkeletonJoint, SkeletonJointPosition&gt; dict = joints.get(<span class="keyword">new</span> Integer(user));

                drawLine(g, dict, SkeletonJoint.HEAD, SkeletonJoint.NECK);

                drawLine(g, dict, SkeletonJoint.LEFT_SHOULDER, SkeletonJoint.TORSO);
                drawLine(g, dict, SkeletonJoint.RIGHT_SHOULDER, SkeletonJoint.TORSO);       
                  ...         
            }
</pre></div><h2><a class="anchor" id="utj_paint">
paint() method</a></h2>
<p>The paint() method manages calling the drawSkeleton() method, using it to actually print the skeleton on the graphic display. </p>
<div class="fragment"><pre class="fragment">            <span class="keywordflow">if</span> (drawPixels)
            {
           DataBufferByte dataBuffer = <span class="keyword">new</span> DataBufferByte(imgbytes, width*height*3);

           WritableRaster raster = Raster.createInterleavedRaster(dataBuffer, width, height, width * 3, 3, <span class="keyword">new</span> <span class="keywordtype">int</span>[]{0, 1, 2}, null); 

           ColorModel colorModel = <span class="keyword">new</span> ComponentColorModel(ColorSpace.getInstance(ColorSpace.CS_sRGB), <span class="keyword">new</span> <span class="keywordtype">int</span>[]{8, 8, 8}, <span class="keyword">false</span>, <span class="keyword">false</span>, ComponentColorModel.OPAQUE, DataBuffer.TYPE_BYTE);

           bimg = <span class="keyword">new</span> BufferedImage(colorModel, raster, <span class="keyword">false</span>, null);

                    g.drawImage(bimg, 0, 0, null);
            }               
</pre></div><p>The following code block gets an array of user IDs of all the recognized users in the scene at the current time. The code then performs the main routine loop for each user in the scene. </p>
<div class="fragment"><pre class="fragment">            <span class="keywordtype">int</span>[] users = userGen.getUsers();
            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; users.length; ++i)
            {
              ... 
            }               
</pre></div><p>The following code block sets a diferent color for the avatar of each user. </p>
<div class="fragment"><pre class="fragment">            Color c = colors[users[i]%colors.length];
            c = <span class="keyword">new</span> Color(255-c.getRed(), 255-c.getGreen(), 255-c.getBlue());

            g.setColor(c);
</pre></div><p>If a user is being tracked, its skeleton is drawn. This is checked with the <a class="el" href="classxn_1_1_skeleton_capability.html#a3d377a980e3c34cc12fd5354ceda89f2">xn::SkeletonCapability::IsTracking()</a> method. </p>
<div class="fragment"><pre class="fragment">            <span class="keywordflow">if</span> (drawSkeleton &amp;&amp; skeletonCap.IsTracking(users[i]))
            {
                drawSkeleton(g, users[i]);
            }
</pre></div><p>The application then prints a status report for the user at the position of the user. It prints it at the user's center of mass location.</p>
<p>The application displays the status report at the user's position. To do this, the application must first get the position of the user's center of mass (CoM). This is the single point for representing the user. This is done by calling the <a class="el" href="classxn_1_1_user_generator.html">xn::UserGenerator</a> node's <a class="el" href="classxn_1_1_user_generator.html#a451c8a197374b567e62622f5edcb1670">getUserCoM()</a> method for each user. The CoM must then be converted to projective coordinates using the <a class="el" href="classxn_1_1_depth_generator.html#a70cda9f296d0ac90088cfafc34e9edd2">convertRealWorldToProjective()</a> method provided by the <a class="el" href="classxn_1_1_depth_generator.html">DepthGenerator</a> node. </p>
<div class="fragment"><pre class="fragment">            Point3D com = depthGen.convertRealWorldToProjective(userGen.getUserCoM(users[i]));
</pre></div><div class="fragment"><pre class="fragment">            String label = null;
            <span class="keywordflow">if</span> (!printState)
            {
                label = <span class="keyword">new</span> String(<span class="stringliteral">&quot;&quot;</span>+users[i]);
            }
            <span class="keywordflow">else</span> <span class="keywordflow">if</span> (skeletonCap.IsTracking(users[i]))
            {
                <span class="comment">// Tracking</span>
                label = <span class="keyword">new</span> String(users[i] + <span class="stringliteral">&quot; - Tracking&quot;</span>);
            }
            <span class="keywordflow">else</span> <span class="keywordflow">if</span> (skeletonCap.isSkeletonCalibrating(users[i]))
            {
                <span class="comment">// Calibrating</span>
                label = <span class="keyword">new</span> String(users[i] + <span class="stringliteral">&quot; - Calibrating&quot;</span>);
            }
            <span class="keywordflow">else</span>
            {
                <span class="comment">// Nothing</span>
                label = <span class="keyword">new</span> String(users[i] + <span class="stringliteral">&quot; - Looking for pose (&quot;</span> + calibPose + <span class="stringliteral">&quot;)&quot;</span>);
            }
</pre></div><p>Each of the above cases is a different state, as described below. A label is set up depending on state, and then displayed on the screen at the user position.</p>
<p>The <a class="el" href="classxn_1_1_skeleton_capability.html#a3d377a980e3c34cc12fd5354ceda89f2">IsTracking()</a> method returns whether a user is currently being tracked. A calibrated user means that the human user's limbs have been measured and the calibration data is available. </p>
<div class="fragment"><pre class="fragment">            <span class="keywordflow">else</span> <span class="keywordflow">if</span> (skeletonCap.IsTracking(users[i]))
</pre></div><p>The <a class="el" href="classxn_1_1_skeleton_capability.html#aa86d9246c806eacb6fd626290d4cf0e7">isSkeletonCalibrating</a> method returns whether a user is being currently calibrated. </p>
<div class="fragment"><pre class="fragment">            <span class="keywordflow">else</span> <span class="keywordflow">if</span> (skeletonCap.isSkeletonCalibrating(users[i]))
</pre></div><p>If a skeleton is not being calibrated or tracked, then in this implementation, the SkeletonCapability is looking for a pose, which is the assumed meaning of the catch-all branch of the if-then-else, as follows. </p>
<div class="fragment"><pre class="fragment">            <span class="keywordflow">else</span>
            {
                <span class="comment">// Nothing</span>
                label = <span class="keyword">new</span> String(users[i] + <span class="stringliteral">&quot; - Looking for pose (&quot;</span> + calibPose + <span class="stringliteral">&quot;)&quot;</span>);
            }           
</pre></div><p>Finally, the application then displays the status starting at the CoM position of the user as follows. </p>
<div class="fragment"><pre class="fragment">            g.drawString(label, (<span class="keywordtype">int</span>)com.getX(), (int)com.getY());
</pre></div> </div>
<hr class="footer"/><address style="text-align: right;"><small>Generated on Wed Jun 13 21:55:36 2012 for OpenNI 1.5.4 by&nbsp;
<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.6.3 </small></address>
</body>
</html>
